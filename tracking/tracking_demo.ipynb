{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import pickle\n",
    "import sys\n",
    "import copy\n",
    "sys.path.append('/Users/jerrytang/.virtualenvs/cv/lib/python2.7/site-packages')\n",
    "\n",
    "import helpers\n",
    "import cluster\n",
    "import evaluation\n",
    "import registration\n",
    "import processing\n",
    "import correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# registration\n",
    "reference_indices = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "match_probability_threshold = 0.2\n",
    "\n",
    "# clustering\n",
    "cluster_cutoff_distance = 0.7\n",
    "cluster_accept_size = 0.001\n",
    "\n",
    "# assignment\n",
    "center_assignment_distance = 100\n",
    "\n",
    "# correction\n",
    "max_interpolation_length = 20\n",
    "frame_occurence_threshold = 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = ['/Users/jerrytang/hydra_data/corrected_100.csv']\n",
    "video_path = '/Users/jerrytang/hydra_data/stk_0001_Substack (1-5000).tif'\n",
    "assignments_read_path = '/Users/jerrytang/hydra_data/motion_assignments.csv'\n",
    "# None if the loaded data set is not motion corrected (corrected map is output of ICY motion correction)\n",
    "motion_correction_map_path = '/Users/jerrytang/hydra_data/map_100.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# res is 2 for 512 images, 1 for 1024\n",
    "res = 2 \n",
    "video_save_folder = '/Users/jerrytang/hydra_data/temp_video'\n",
    "assignments_save_path = '/Users/jerrytang/hydra_data/corrected_assignments.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "full = helpers.load_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vid = io.imread(video_path)[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute New Motion Corrected Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# registration[time][spot] = vector representation of that spot\n",
    "registrations = registration.get_soft_registration(full, reference_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flat array of nonzero spot vectors\n",
    "clustering_subset = cluster.get_subset(registrations, clustering_subset_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cluster_assignments[index] is the cluster that the vector at clustering_subset[index] is assigned to\n",
    "cluster_assignments = cluster.correlation_hac(clustering_subset, cluster_cutoff_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clusters[i] = list of indices in clustering_subset for vectors assigned to cluster i\n",
    "clusters = cluster.reverse_map(cluster_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# centers[i] = vector representing the center for the cluster of neuron i\n",
    "test_cluster_accept_size = 0.0005\n",
    "centers = cluster.get_centers(clusters, clustering_subset, test_cluster_accept_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# time_assignments[time] = map from spot index to (neuron index, distance)\n",
    "time_assignments = cluster.assign_neurons(registrations, centers, center_assignment_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# neurons[n][time] = location of neuron n at time t\n",
    "neurons = cluster.process_assignments(time_assignments, len(centers), full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if input neurons were motion corrected use corresponding map to translate back into original space\n",
    "if motion_correction_map_path != None:\n",
    "    correction_map = processing.load_correction_map(\"/Users/jerrytang/0_hydra_data/map_100.csv\")\n",
    "    neurons = processing.reverse_correction(neurons, correction_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corrected_full = processing.reverse_full_correction(full, correction_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(corrected_full)):\n",
    "    corrected_full[i] = np.asarray(corrected_full[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get distribution of path lengths\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "plt.hist(list(map(lambda x : len(x), neurons)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gap_corrected = correction.gap_interpolation(neurons, max_interpolation_length, corrected_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jump_corrected = correction.jump_interpolation(gap_corrected, max_interpolation_length, corrected_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consistent_tracks = correction.filter_consistent_tracks(jump_corrected, 5.0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get distribution of path lengths\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "plt.hist(list(map(lambda x : len(x), consistent_tracks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assignments_save_path = '/Users/jerrytang/hydra_data/soft.csv'\n",
    "helpers.write_neuron_assignments(neurons, assignments_save_path, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracks = evaluation.track_complete(vid, consistent_frame_occurance_filtered, res)\n",
    "video_save_folder = '/Users/jerrytang/hydra_data'\n",
    "evaluation.save_vid(tracks, video_save_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
